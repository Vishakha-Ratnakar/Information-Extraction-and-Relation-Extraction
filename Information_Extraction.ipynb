{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEpjx2qKnyBl"
      },
      "source": [
        "---\n",
        "\n",
        "## Information Extraction and Relation Extraction\n",
        "\n",
        "In the following tasks you will write code to perform **_information extraction_** and **_relation extraction_** across a collection of documents in `movies.zip`.\n",
        "\n",
        "The zip archive contains 100 files, out of which 50 are plaintext documents and other 50 contain data structured as JSON.\n",
        "Each plaintext document contains a text description of a movie taken from the English version of Wikipedia, while each JSON document contains *gold-standard* labels (also called *reference* labels) stored as key-value pairs for the entities and relations for each document.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXzoZVNZyevs"
      },
      "outputs": [],
      "source": [
        "!if test -f \"movies.zip\"; then rm \"movies.zip\"; fi\n",
        "!if test -d \"movies/\"; then rm -rf \"movies/\"; fi\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1L6NcSGkubNJaL6xSnYEZZKSrlyXq1AbB\" -O \"movies.zip\"\n",
        "!unzip \"movies.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm1emJILzF5K"
      },
      "source": [
        "---\n",
        "\n",
        "## Reading Data\n",
        "\n",
        "Place the unzipped `movies` directory in the same location as this notebook and run the following code cell to read the plaintext and JSON documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5hzct-HzUvJ"
      },
      "outputs": [],
      "source": [
        "######### DO NOT EDIT THIS CELL #########\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "documents = []   # store the text documents as a list of strings\n",
        "labels = []      # store the gold-standard labels as a list of dictionaries\n",
        "\n",
        "for idx in range(50):\n",
        "  with open(os.path.join('movies', str(idx+1).zfill(2) + '.doc.txt')) as f:\n",
        "    doc = f.read().strip()\n",
        "  with open(os.path.join('movies', str(idx+1).zfill(2) + '.info.json')) as f:\n",
        "    label = json.load(f)\n",
        "\n",
        "  documents.append(doc)\n",
        "  labels.append(label)\n",
        "\n",
        "assert len(documents) == 50\n",
        "assert len(labels) == 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnmnLhDyj2eG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPCKvyYFj0zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48b03d5-a98f-42da-fcc6-169b251dc567"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Load the libraries which might be useful\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('all', quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "899-kd7LmlFp"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 1: Document Pre-processing \n",
        "Write a function that takes a document and returns a list of sentences with part-of-speech tags.\n",
        "\n",
        "The expected output is a list of tagged sentences where each tagged sentence is a list containing `(token, tag)` pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB8R43AklZxO"
      },
      "outputs": [],
      "source": [
        "def ie_preprocess(document):\n",
        "  '''Return a list of sentences tagged with part-of-speech tags for the given document.'''\n",
        "\n",
        "  tagged_sentences = []\n",
        "\n",
        "  # your code goes here\n",
        "  # ...\n",
        "  sentences = nltk.sent_tokenize(document)\n",
        "\n",
        "  tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "  tagged_sentences = [nltk.pos_tag(sent) for sent in tokenized_sentences]\n",
        "\n",
        "  return tagged_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KJLD-AMMvdq"
      },
      "source": [
        "Run the cell below to check if the output is formatted correctly.\n",
        "\n",
        "Expected output: `[('It', 'PRP'), ('received', 'VBD'), ('ten', 'JJ'), ('Oscar', 'NNP'), ('nominations', 'NNS'), ('(', '('), ('including', 'VBG'), ('Best', 'NNP'), ('Picture', 'NN'), (')', ')'), (',', ','), ('winning', 'VBG'), ('seven', 'CD'), ('.', '.')]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sEQYa3TBDYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b8ee41-bca4-4c9a-ebb0-4fbbb3734646"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('It', 'PRP'),\n",
              " ('received', 'VBD'),\n",
              " ('ten', 'JJ'),\n",
              " ('Oscar', 'NNP'),\n",
              " ('nominations', 'NNS'),\n",
              " ('(', '('),\n",
              " ('including', 'VBG'),\n",
              " ('Best', 'NNP'),\n",
              " ('Picture', 'NN'),\n",
              " (')', ')'),\n",
              " (',', ','),\n",
              " ('winning', 'VBG'),\n",
              " ('seven', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# check output for Task 1\n",
        "ie_preprocess(documents[0])[-10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgEPCLXmq8bC"
      },
      "source": [
        "## Task 2: Named Entity Recognition\n",
        "\n",
        "Write a function that returns a list of all the named entities in a given document. The document here is structured as a list of sentences and tagged with part-of-speech tags.\n",
        "\n",
        "Hint: Set `binary = True` while calling the `ne_chunk` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHKjz5TKp5uM"
      },
      "outputs": [],
      "source": [
        "def find_named_entities(tagged_document):\n",
        "  '''Return a list of all the named entities in the given tagged document.'''\n",
        "  \n",
        "\n",
        "\n",
        "  # your code goes here\n",
        "  # ...\n",
        "  named_entities = []\n",
        "  \n",
        "  tree = nltk.ne_chunk_sents(tagged_document, binary=True)\n",
        "  for tree in tree:\n",
        "    for subtree in tree.subtrees():\n",
        "      if subtree.label() == \"NE\":\n",
        "        entity = \"\"\n",
        "        for leaf in subtree.leaves():\n",
        "          entity = entity + leaf[0] + \" \"\n",
        "        named_entities.append(entity.strip())\n",
        "\n",
        "  return named_entities\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvZNyV-ENDZc"
      },
      "source": [
        "Run the cell below to check if the output is formatted correctly.\n",
        "\n",
        "The output values might not match exactly, but should look similar to: `['Star Wars', 'Star Wars', 'New Hope', 'American', 'George Lucas', 'Lucasfilm', ...]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnlqsKg7sk29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f39647-5eb6-4947-d0b2-2ce75581cdf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Star Wars',\n",
              " 'Star Wars',\n",
              " 'New Hope',\n",
              " 'American',\n",
              " 'George Lucas',\n",
              " 'Lucasfilm',\n",
              " 'Century Fox',\n",
              " 'Mark Hamill',\n",
              " 'Harrison Ford',\n",
              " 'Carrie Fisher']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# check output for Task 2\n",
        "tagged_document = ie_preprocess(documents[0]) # pre-process the first document\n",
        "find_named_entities(tagged_document)[:10]     # display the first 10 named entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmpuu0yvwI_X"
      },
      "source": [
        "## Task 3: Information / Relation Extraction (I) \n",
        "\n",
        "Choose any **three** relations out of the following and write functions to extract them from a given document.\n",
        "\n",
        "* **Title**\n",
        "* **Language**\n",
        "* **Starring**\n",
        "* **Release date**\n",
        "* **Cinematography**\n",
        "* **Dialogue by**\n",
        "* **Directed by**\n",
        "* **Edited by**\n",
        "* **Music by**\n",
        "* **Narrated by**\n",
        "* **Produced by**\n",
        "* **Screenplay by**\n",
        "* **Story by**\n",
        "* **Written by**\n",
        "* **Production companies**\n",
        "* **Distribution companies**\n",
        "* **Budget**\n",
        "* **Box office**\n",
        "\n",
        "\n",
        "The functions you define here must take as input a string called `document` and return the information/relation extracted as a list. You can explain your approach with comments along with your code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw8YQAr-wwFM"
      },
      "outputs": [],
      "source": [
        "# relation 1 - your code goes here\n",
        "def Written_by(document):\n",
        "\n",
        " #the class of subject named entity\n",
        " subject_class = 'NE'   \n",
        "\n",
        " #pattern for extracting written by relation \n",
        " pattern = re.compile(r'.*\\bwritten\\b.*',re.IGNORECASE) \n",
        "\n",
        " #The class of object named entity \n",
        " object_class = 'NE'  \n",
        "\n",
        " written = [] #stores the ouput list\n",
        "\n",
        " tagged_sentences = ie_preprocess(document)\n",
        "\n",
        " for sent in tagged_sentences:\n",
        "  \n",
        "  # chunk each sent of tagged documents\n",
        "  chunked_sent = nltk.ne_chunk(sent, binary = True) \n",
        "\n",
        "  #Group a chunk structure into a list of 'semi-relations'\n",
        "  pairs = nltk.sem.relextract.tree2semi_rel(chunked_sent)  \n",
        "\n",
        "  #Converts the pairs generated into a 'reldict': a dictionary which\n",
        "  #stores information about the subject and object NEs plus the filler between them.\n",
        "  reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])   \n",
        "\n",
        "\n",
        "  relfilter = lambda x: (x['subjclass'] == subject_class and\n",
        "                           pattern.match(x['filler']) and\n",
        "                           x['objclass'] == object_class)\n",
        "\n",
        "  rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "  for rel in rels:\n",
        "    written.append(rel['objsym'].replace(\"_\", \" \").title())\n",
        "    \n",
        " return written"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-LRnjy810ZR"
      },
      "outputs": [],
      "source": [
        "def directed_by(document):\n",
        "\n",
        " #the class of subject named entity\n",
        " subject_class = 'NE'\n",
        "\n",
        " #pattern for extracting written by relation\n",
        " pattern = re.compile(r'.*\\bdirected\\b.*',re.IGNORECASE)\n",
        "\n",
        " #The class of object named entity \n",
        " object_class = 'NE'\n",
        "\n",
        " directed = []  #stores the ouput list\n",
        "\n",
        " tagged_sentences = ie_preprocess(document)\n",
        "\n",
        " for sent in tagged_sentences:\n",
        "\n",
        "  # chunk each sent of tagged documents\n",
        "  chunked_sent = nltk.ne_chunk(sent, binary = True) \n",
        "\n",
        "  #Group a chunk structure into a list of 'semi-relations'\n",
        "  pairs = nltk.sem.relextract.tree2semi_rel(chunked_sent)\n",
        "\n",
        "  #Converts the pairs generated into a 'reldict': a dictionary which\n",
        "  #stores information about the subject and object NEs plus the filler between them.\n",
        "  reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "  relfilter = lambda x: (x['subjclass'] == subject_class and\n",
        "                           pattern.match(x['filler']) and\n",
        "                           x['objclass'] == object_class)\n",
        "\n",
        "  rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "\n",
        "  for rel in rels:\n",
        "    directed.append(rel['objsym'].replace(\"_\", \" \").title())\n",
        "\n",
        " return directed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Distribution(document):\n",
        "\n",
        " #the class of subject named entity\n",
        " subject_class = 'NE'\n",
        "\n",
        " #pattern for extracting written by relation\n",
        " pattern = re.compile(r'.*\\bdistributed\\b.*',re.IGNORECASE)\n",
        "\n",
        " #The class of object named entity\n",
        " object_class = 'NE'\n",
        "\n",
        " distributed = [] #stores the ouput list\n",
        "\n",
        " tagged_sentences = ie_preprocess(document)\n",
        "\n",
        " for sent in tagged_sentences:\n",
        "\n",
        "  # chunk each sent of tagged documents\n",
        "  chunked_sent = nltk.ne_chunk(sent, binary = True) \n",
        "\n",
        "  #Group a chunk structure into a list of 'semi-relations'\n",
        "  pairs = nltk.sem.relextract.tree2semi_rel(chunked_sent)\n",
        "\n",
        "  #Converts the pairs generated into a 'reldict': a dictionary which\n",
        "  #stores information about the subject and object NEs plus the filler between them.\n",
        "  reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "\n",
        "  relfilter = lambda x: (x['subjclass'] == subject_class and\n",
        "                           pattern.match(x['filler']) and\n",
        "                           x['objclass'] == object_class)\n",
        "\n",
        "  rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "  for rel in rels:\n",
        "    distributed.append(rel['objsym'].replace(\"_\", \" \").title())\n",
        "\n",
        " return distributed"
      ],
      "metadata": {
        "id": "UzGWsxL7eZKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuJmr-eKvrQ3"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 4: Information / Relation Extraction (II)  \n",
        "\n",
        "Identify one other relation of your choice, besides the ones mentioned in the previous task, and write a function to extract it. \n",
        "\n",
        "The function you define here must take as input a string called `document` and return the information/relations extracted as a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kncUM3pHvyAT"
      },
      "outputs": [],
      "source": [
        "def Awards_Won(document):\n",
        "\n",
        " subject_class = 'NE'\n",
        " pattern = re.compile(r'.*\\bwon\\b.*',re.IGNORECASE)\n",
        " object_class = 'NE'\n",
        "\n",
        " award = []\n",
        "\n",
        " tagged_sentences = ie_preprocess(document)\n",
        "\n",
        " for sent in tagged_sentences:\n",
        "  chunked_sent = nltk.ne_chunk(sent, binary = True) \n",
        "  pairs = nltk.sem.relextract.tree2semi_rel(chunked_sent)\n",
        "\n",
        "  reldicts = nltk.sem.relextract.semi_rel2reldict(pairs + [[[]]])\n",
        "  relfilter = lambda x: (x['subjclass'] == subject_class and\n",
        "                           pattern.match(x['filler']) and\n",
        "                           x['objclass'] == object_class)\n",
        "\n",
        "  rels = list(filter(relfilter, reldicts))\n",
        "\n",
        "  for rel in rels:\n",
        "    award.append(rel['objsym'].replace(\"_\", \" \").title())\n",
        "\n",
        "\n",
        "\n",
        " return award"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIfQCd_Y1x5B"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 5: Combining information in the output \n",
        "\n",
        "Edit the function below to return a Python dictionary with the outputs from the functions defined in tasks $3 - 4$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE_8ptxp-1y4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c90e0f-7c23-417f-ca65-7b88e1287163"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Directed by': ['Steven Spielberg'],\n",
              " 'Distributed companies': ['North America'],\n",
              " 'Task 4': ['Spielberg'],\n",
              " 'Written by': ['Robert Rodat']}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "def extract_info(document):\n",
        "  '''Extract information and relations from a given document.'''\n",
        "\n",
        "  # Edit the output dict below and assign the values to keys by \n",
        "  # calling the appropriate functions from Tasks 3 and 4.\n",
        "  \n",
        "  # You can delete the keys for which you do not perform extraction in Task 3.\n",
        "\n",
        "  output = {\n",
        "    ##### EDIT BELOW THIS LINE #####\n",
        "    \n",
        "    # For the relations you extract in Task 3, \n",
        "    # save the output in the appropriate key and delete rest of the keys.\n",
        "    \n",
        "    \"Directed by\": directed_by(document),\n",
        "    \"Distributed companies\": Distribution(document),\n",
        "    \"Written by\": Written_by(document),\n",
        "\n",
        "    # save the output from Task 4 here\n",
        "    \"Task 4\": Awards_Won(document),\n",
        "\n",
        "    ##### EDIT ABOVE THIS LINE #####\n",
        "  }\n",
        "\n",
        "  return output\n",
        "\n",
        "\n",
        "# check output for the first document\n",
        "\n",
        "extract_info(documents[7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHv5pRQ7BKJo"
      },
      "source": [
        "The output from the cell above should look something like the dictionary shown below. Overall values might be different, based on what four items you choose to extract in Tasks 3 and 4, but the structure should be similar.\n",
        "\n",
        "For example, if you choose to extract **Starring**, **Release Date**, **Box office**, and **Directed by**, then the output should look something like this for the first document:\n",
        "\n",
        "```javascript\n",
        "{\n",
        "  'Box office': ['$775 million'],\n",
        "  'Directed by': ['George Lucas'],\n",
        "  'Release date': ['May 25, 1977'],\n",
        "  'Starring': ['Mark Hamill', 'Harrison Ford', 'Carrie Fisher', \n",
        "               'Peter Cushing', 'David Prowse', 'James Earl Jones', ],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDMhFQq4fBnf"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 6: Evaluation (I)\n",
        "\n",
        "Write a function to evaluate the performance of Task $3$ using **Precision**, **Recall** and **F1** scores. Use the gold-standard labels provided in the JSON files to calculate these values.\n",
        "\n",
        "Please note that not all the information / relations mentioned in Task $3$ have associated labels for each and every movie in the JSON documents, i.e., some JSON documents will have certain keys-value pairs missing. For example, we have labels for *Budget* in 46 out of the 50 movies and in the remaining 4 documents, you will find that the key `Budget` is omitted from the JSON.\n",
        " \n",
        "Also keep in mind that we will further run this evaluation on a hidden test set containing similar movie descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvJ9OhnDe7ML"
      },
      "outputs": [],
      "source": [
        "from itertools import zip_longest\n",
        "def evaluate(labels, predictions):\n",
        "  '''\n",
        "  Evaluate the performance of relation extraction \n",
        "  using Precision, Recall, and F1 scores.\n",
        "\n",
        "  Args:\n",
        "    labels: A list containing gold-standard labels\n",
        "    predictions: A list containing information extracted from documents\n",
        "  Returns:\n",
        "    scores: A dictionary containing Precision, Recall and F1 scores \n",
        "            for the information/relations extracted in Task 3.\n",
        "  '''\n",
        "\n",
        "  assert len(predictions) == len(labels)\n",
        "\n",
        "  scores = {\n",
        "      'precision': 0.0, 'recall': 0.0, 'f1': 0.0\n",
        "  }\n",
        "\n",
        "  # calculate the precision, recall and f1 score over the information fields \n",
        "  # corresponding to Task 3 and store the result in the `scores` dict.\n",
        "\n",
        "  # your code goes here\n",
        "  # ...\n",
        "\n",
        "\n",
        "  true_positive = prec = reca = 0   # initialize to zero\n",
        "\n",
        "\n",
        "  for predictions, label in zip_longest(predictions, labels):\n",
        "    for key, value in predictions.items():\n",
        "    \n",
        "      predictions_set = set(list(predictions[key]))\n",
        "      if key in label:\n",
        "        label_set = set(list(label[key]))\n",
        "        true_positive = true_positive + len(predictions_set & label_set)\n",
        "        prec = prec + len(predictions_set)\n",
        "        reca = reca + len(label_set)\n",
        "\n",
        "  scores['precision'] = round((true_positive / prec),2)\n",
        "  scores['recall'] = round((true_positive / reca),2)\n",
        "  scores['f1'] = 2 * round(((scores['precision'] * scores['recall']) / (scores['precision'] + scores['recall'])),3) \n",
        "\n",
        "  return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA39EbBCfRu6"
      },
      "source": [
        "---\n",
        "Run the cell below to calculate and display the evaluation scores for the 50 documents in `movies.zip`.\n",
        "\n",
        "You can consider the following as a baseline score. Your aim should be to score higher or atleast get as close as possible to these values.\n",
        "\n",
        "| Precision | Recall | F1    |\n",
        "| :---:     | :---:  | :---: |\n",
        "| 0.5       | 0.25   | 0.333 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRxOd4dIfRu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "582263ec-29e9-4180-ffb1-f8c21078146b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ba8bca92-921c-4958-8de4-9938c37cb597\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.79</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.574</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba8bca92-921c-4958-8de4-9938c37cb597')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba8bca92-921c-4958-8de4-9938c37cb597 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba8bca92-921c-4958-8de4-9938c37cb597');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   precision  recall     f1\n",
              "0       0.79    0.45  0.574"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "# calculate evaluation score across all the 50 documents\n",
        "extracted_infos = []\n",
        "for document in documents:\n",
        "  extracted_infos.append(extract_info(document))\n",
        "\n",
        "scores = evaluate(labels, extracted_infos)\n",
        "\n",
        "pd.DataFrame([scores])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agNQPVqG5aoS"
      },
      "source": [
        "---\n",
        "\n",
        "## Task 7: Evaluation (II) (10 Marks)\n",
        "\n",
        "Describe **two** challenges you encountered above or might encounter in the evaluation of *information extraction* or *relation extraction* tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdKI5J-fF1g"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "> \n",
        "1. There are just a few files among the specified JSON files that have the key-value pair written by. When we extract written by relation from the corpus, we get roughly 30 names. The return relation is not counted during evaluation because there is no key-value pair for written, which reduces precision.\n",
        "\n",
        "2. Using the common pattern \"produced,\" the relations \"produced by\" and \"producing companies\" are retrieved. They both produce the same-named entity E.g., document 1 returns \"Lucasfilm\" for both the relationships. resulting in less precision."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Information_Extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}